{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "0BQdnNmKQHIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa5caee-ad06-4c6d-a08e-1a0c780651b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx7e83XEbaR4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/ML_Labs/Lab_4/advertising.csv')\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-eDgcY_xbjea",
        "outputId": "24103c08-e09b-4084-e06d-02b735470fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Daily Time Spent on Site  Age  Area Income  Daily Internet Usage  \\\n",
              "0                     68.95   35     61833.90                256.09   \n",
              "1                     80.23   31     68441.85                193.77   \n",
              "2                     69.47   26     59785.94                236.50   \n",
              "3                     74.15   29     54806.18                245.89   \n",
              "4                     68.37   35     73889.99                225.58   \n",
              "\n",
              "                           Ad Topic Line            City  Male     Country  \\\n",
              "0     Cloned 5thgeneration orchestration     Wrightburgh     0     Tunisia   \n",
              "1     Monitored national standardization       West Jodi     1       Nauru   \n",
              "2       Organic bottom-line service-desk        Davidton     0  San Marino   \n",
              "3  Triple-buffered reciprocal time-frame  West Terrifurt     1       Italy   \n",
              "4          Robust logistical utilization    South Manuel     0     Iceland   \n",
              "\n",
              "             Timestamp  Clicked on Ad  \n",
              "0  2016-03-27 00:53:11              0  \n",
              "1  2016-04-04 01:39:02              0  \n",
              "2  2016-03-13 20:35:42              0  \n",
              "3  2016-01-10 02:31:19              0  \n",
              "4  2016-06-03 03:36:18              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85b56d5c-4037-4612-9545-6c69870ce873\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Daily Time Spent on Site</th>\n",
              "      <th>Age</th>\n",
              "      <th>Area Income</th>\n",
              "      <th>Daily Internet Usage</th>\n",
              "      <th>Ad Topic Line</th>\n",
              "      <th>City</th>\n",
              "      <th>Male</th>\n",
              "      <th>Country</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Clicked on Ad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68.95</td>\n",
              "      <td>35</td>\n",
              "      <td>61833.90</td>\n",
              "      <td>256.09</td>\n",
              "      <td>Cloned 5thgeneration orchestration</td>\n",
              "      <td>Wrightburgh</td>\n",
              "      <td>0</td>\n",
              "      <td>Tunisia</td>\n",
              "      <td>2016-03-27 00:53:11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80.23</td>\n",
              "      <td>31</td>\n",
              "      <td>68441.85</td>\n",
              "      <td>193.77</td>\n",
              "      <td>Monitored national standardization</td>\n",
              "      <td>West Jodi</td>\n",
              "      <td>1</td>\n",
              "      <td>Nauru</td>\n",
              "      <td>2016-04-04 01:39:02</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69.47</td>\n",
              "      <td>26</td>\n",
              "      <td>59785.94</td>\n",
              "      <td>236.50</td>\n",
              "      <td>Organic bottom-line service-desk</td>\n",
              "      <td>Davidton</td>\n",
              "      <td>0</td>\n",
              "      <td>San Marino</td>\n",
              "      <td>2016-03-13 20:35:42</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>74.15</td>\n",
              "      <td>29</td>\n",
              "      <td>54806.18</td>\n",
              "      <td>245.89</td>\n",
              "      <td>Triple-buffered reciprocal time-frame</td>\n",
              "      <td>West Terrifurt</td>\n",
              "      <td>1</td>\n",
              "      <td>Italy</td>\n",
              "      <td>2016-01-10 02:31:19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>68.37</td>\n",
              "      <td>35</td>\n",
              "      <td>73889.99</td>\n",
              "      <td>225.58</td>\n",
              "      <td>Robust logistical utilization</td>\n",
              "      <td>South Manuel</td>\n",
              "      <td>0</td>\n",
              "      <td>Iceland</td>\n",
              "      <td>2016-06-03 03:36:18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85b56d5c-4037-4612-9545-6c69870ce873')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85b56d5c-4037-4612-9545-6c69870ce873 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85b56d5c-4037-4612-9545-6c69870ce873');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3ce90d7-a4dc-424d-bad0-4e841dcb3070\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3ce90d7-a4dc-424d-bad0-4e841dcb3070')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3ce90d7-a4dc-424d-bad0-4e841dcb3070 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Daily Time Spent on Site\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.8536145675002,\n        \"min\": 32.6,\n        \"max\": 91.43,\n        \"num_unique_values\": 900,\n        \"samples\": [\n          46.13,\n          78.79,\n          53.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 19,\n        \"max\": 61,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          58,\n          25,\n          43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Area Income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13414.634022282358,\n        \"min\": 13996.5,\n        \"max\": 79484.8,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          54787.37,\n          41521.28,\n          61757.12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Daily Internet Usage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43.902339301980106,\n        \"min\": 104.78,\n        \"max\": 269.96,\n        \"num_unique_values\": 966,\n        \"samples\": [\n          223.09,\n          219.49,\n          142.21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ad Topic Line\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Customizable holistic archive\",\n          \"Self-enabling zero administration neural-net\",\n          \"Quality-focused maximized extranet\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 969,\n        \"samples\": [\n          \"Lake Elizabethside\",\n          \"Charlottefort\",\n          \"New Jasmine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Male\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 237,\n        \"samples\": [\n          \"Angola\",\n          \"Spain\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"2016-03-02 04:02:45\",\n          \"2016-01-05 11:53:17\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clicked on Ad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(y):\n",
        "  if isinstance(y, pd.Series):\n",
        "    a = y.value_counts()/y.shape[0]\n",
        "    entropy = np.sum(-a*np.log2(a+1e-9))\n",
        "    return(entropy)\n",
        "  else:\n",
        "    raise('Object must be a Pandas Series.')\n",
        "\n",
        "entropy(data.Male)"
      ],
      "metadata": {
        "id": "jgG6y0OWb9-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variance(y):\n",
        "  if(len(y) == 1):\n",
        "    return 0\n",
        "  else:\n",
        "    return y.var()\n",
        "\n",
        "def information_gain(y, mask, func=entropy):\n",
        "  a = sum(mask)\n",
        "  b = mask.shape[0] - a\n",
        "\n",
        "  if(a == 0 or b ==0):\n",
        "    gain = 0\n",
        "  else:\n",
        "    if y.dtypes != 'O':\n",
        "      gain = variance(y) - (a/(a+b)* variance(y[mask])) - (b/(a+b)*variance(y[-mask]))\n",
        "    else:\n",
        "      gain = func(y)-a/(a+b)*func(y[mask])-b/(a+b)*func(y[-mask])\n",
        "\n",
        "  return gain"
      ],
      "metadata": {
        "id": "Y3JVr9Q1eOh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "information_gain(dataset['Clicked on Ad'], dataset['Male'] == 1)"
      ],
      "metadata": {
        "id": "M4HaCkUvfJ9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To calculate the best split of a numeric variable, first, all possible values that the variable is taking must be obtained. Once we have the options, for each option we will calculate the Information Gain using as a filter if the value is less than that value. Obviously, the first possible data will be drop, because the split will include all values.\n",
        "\n",
        "In case we have categorical variables, the idea is the same, only that in this case we will have to calculate the Information Gain for all possible combinations of that variable, excluding the option that includes all the options (since it would not be doing any split). This is quite computationally costly if we have a high number of categories, that decision tree algorithms usually only accept categorical variables with less than 20 categories.\n",
        "\n",
        "So, once we have all the splits, we will stick with the split that generates the highest Information Gain."
      ],
      "metadata": {
        "id": "0acYM1xOkjME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_options(a):\n",
        "  #Creates all possible combinations from a Pandas Series.\n",
        "\n",
        "  a = a.unique()\n",
        "\n",
        "  opciones = []\n",
        "  for L in range(0, len(a)+1):\n",
        "      for subset in itertools.combinations(a, L):\n",
        "          subset = list(subset)\n",
        "          opciones.append(subset)\n",
        "\n",
        "  return opciones[1:-1]\n",
        "\n",
        "def max_information_gain_split(x, y, func=entropy):\n",
        "\n",
        "  split_value = []\n",
        "  gain = []\n",
        "\n",
        "  numeric_variable = True if x.dtypes != 'O' else False\n",
        "\n",
        "  if numeric_variable:\n",
        "    options = x.sort_values().unique()[1:]\n",
        "  else:\n",
        "    options = categorical_options(x)\n",
        "\n",
        "  # Calculate gain for all values\n",
        "  for val in options:\n",
        "    mask =   x < val if numeric_variable else x.isin(val)\n",
        "    val_gain = information_gain(y, mask, func)\n",
        "    # Append results\n",
        "    gain.append(val_gain)\n",
        "    split_value.append(val)\n",
        "\n",
        "  if len(gain) == 0:\n",
        "    return(None,None,None,False)\n",
        "\n",
        "  else:\n",
        "    best_gain = max(gain)\n",
        "    best_gain_index = gain.index(best_gain)\n",
        "    best_split = split_value[best_gain_index]\n",
        "    return(best_gain,best_split,numeric_variable, True)\n",
        "\n",
        "age_gain, age_split, _, _ = max_information_gain_split(dataset['Age'], dataset['Clicked on Ad'],)\n",
        "\n",
        "print(\n",
        "  \"The best split for Age is when the variable is less than \",\n",
        "  age_split,\"\\nInformation Gain for that split is:\", age_gain)"
      ],
      "metadata": {
        "id": "69aAcXJvfLF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "best split will be the one that generates the highest Information Gain. To know which one is it, we simply have to calculate the Information Gain for each of the predictor variables of the model."
      ],
      "metadata": {
        "id": "IT19uJ7jbzRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.drop('Clicked on Ad', axis= 1).apply(max_information_gain_split, y = dataset['Clicked on Ad'])"
      ],
      "metadata": {
        "id": "NnF-X9ezfrVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Training"
      ],
      "metadata": {
        "id": "HQYyhTfDcNzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_split(y, dataset):\n",
        "  masks = dataset.drop(y, axis= 1).apply(max_information_gain_split, y = dataset[y])\n",
        "  if sum(masks.loc[3,:]) == 0:\n",
        "    return(None, None, None, None)\n",
        "\n",
        "  else:\n",
        "    # Get only masks that can be splitted\n",
        "    masks = masks.loc[:,masks.loc[3,:]]\n",
        "\n",
        "    # Get the results for split with highest IG\n",
        "    split_variable = masks.iloc[0].astype(np.float32).idxmax()\n",
        "    #split_valid = masks[split_variable][]\n",
        "    split_value = masks[split_variable][1]\n",
        "    split_gain = masks[split_variable][0]\n",
        "    split_numeric = masks[split_variable][2]\n",
        "\n",
        "    return(split_variable, split_value, split_ig, split_numeric)\n",
        "\n",
        "\n",
        "def make_split(variable, value, dataset, is_numeric):\n",
        "  if is_numeric:\n",
        "    dataset_1 = dataset[dataset[variable] < value]\n",
        "    dataset_2 = dataset[(dataset[variable] < value) == False]\n",
        "  else:\n",
        "    dataset_1 = dataset[dataset[variable].isin(value)]\n",
        "    dataset_2 = dataset[(dataset[variable].isin(value)) == False]\n",
        "\n",
        "  return(dataset_1,dataset_2)\n",
        "\n",
        "\n",
        "def make_prediction(dataset, target_factor):\n",
        "  if target_factor:\n",
        "    pred = dataset.value_counts().idxmax()\n",
        "  else:\n",
        "    pred = dataset.mean()\n",
        "\n",
        "  return pred"
      ],
      "metadata": {
        "id": "NDeoGbwffwVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_tree(dataset,y, target_factor, max_depth = None,min_samples_split = None, min_information_gain = 1e-20, counter=0, max_categories = 20):\n",
        "\n",
        "  if counter==0:\n",
        "    types = dataset.dtypes\n",
        "    check_columns = types[types == \"object\"].index\n",
        "    for column in check_columns:\n",
        "      var_length = len(dataset[column].value_counts())\n",
        "      if var_length > max_categories:\n",
        "        raise ValueError('The variable ' + column + ' has '+ str(var_length) + ' unique values, which is more than the accepted ones: ' +  str(max_categories))\n",
        "\n",
        "  if max_depth == None:\n",
        "    depth_cond = True\n",
        "\n",
        "  else:\n",
        "    if counter < max_depth:\n",
        "      depth_cond = True\n",
        "\n",
        "    else:\n",
        "      depth_cond = False\n",
        "\n",
        "  if min_samples_split == None:\n",
        "    sample_cond = True\n",
        "\n",
        "  else:\n",
        "    if dataset.shape[0] > min_samples_split:\n",
        "      sample_cond = True\n",
        "\n",
        "    else:\n",
        "      sample_cond = False\n",
        "\n",
        "  if depth_cond & sample_cond:\n",
        "    var,val,gain,var_type = get_best_split(y, dataset)\n",
        "\n",
        "    if gain is not None and gain >= min_information_gain:\n",
        "      counter += 1\n",
        "      left,right = make_split(var, val, dataset,var_type)\n",
        "\n",
        "      # Instantiate sub-tree\n",
        "      split_type = \"<=\" if var_type else \"in\"\n",
        "      question =   \"{} {}  {}\".format(var,split_type,val)\n",
        "      # question = \"\\n\" + counter*\" \" + \"|->\" + var + \" \" + split_type + \" \" + str(val)\n",
        "      subtree = {question: []}\n",
        "\n",
        "      # Find answers (recursion)\n",
        "      yes_answer = train_tree(left,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
        "\n",
        "      no_answer = train_tree(right,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
        "\n",
        "      if yes_answer == no_answer:\n",
        "        subtree = yes_answer\n",
        "\n",
        "      else:\n",
        "        subtree[question].append(yes_answer)\n",
        "        subtree[question].append(no_answer)\n",
        "\n",
        "    else:\n",
        "      pred = make_prediction(dataset[y],target_factor)\n",
        "      return pred\n",
        "\n",
        "  else:\n",
        "    pred = make_prediction(dataset[y],target_factor)\n",
        "    return pred\n",
        "\n",
        "  return subtree\n",
        "\n",
        "max_depth = 5\n",
        "min_samples_split = 20\n",
        "min_information_gain  = 1e-5\n",
        "\n",
        "decision = train_tree(dataset,'Clicked on Ad',True, max_depth,min_samples_split,min_information_gain)\n",
        "\n",
        "decision"
      ],
      "metadata": {
        "id": "JKa85PL9f5x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_data(observation, tree):\n",
        "  question = list(tree.keys())[0]\n",
        "\n",
        "  if question.split()[1] == '<=':\n",
        "    if observation[question.split()[0]] <= float(question.split()[2]):\n",
        "      answer = tree[question][0]\n",
        "    else:\n",
        "      answer = tree[question][1]\n",
        "  else:\n",
        "    if observation[question.split()[0]] in (question.split()[2]):\n",
        "      answer = tree[question][0]\n",
        "    else:\n",
        "      answer = tree[question][1]\n",
        "\n",
        "  if not isinstance(answer, dict):\n",
        "    return answer\n",
        "  else:\n",
        "    residual_tree = answer\n",
        "    return classify_data(observation, answer)"
      ],
      "metadata": {
        "id": "ijE2EwQng05D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASKS:\n",
        "\n",
        "\n",
        "1.   Implement decision tree algorithm on a dataset of your choice.\n",
        "2.   Instead of Entropy, use GINI INDEX and observe the performance for any difference(s).\n",
        "3.   Employ SciKit Learn implementation of decision tree and plot it. Observe for any difference(s)."
      ],
      "metadata": {
        "id": "YBuDQLQOffHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('advertising.csv')\n",
        "\n",
        "# ---- Task 1: Implement decision tree algorithm ----\n",
        "\n",
        "# Fix the entropy function\n",
        "def entropy(y):\n",
        "    if isinstance(y, pd.Series):\n",
        "        a = y.value_counts()/y.shape[0]\n",
        "        entropy = np.sum(-a*np.log2(a+1e-9))\n",
        "        return entropy\n",
        "    else:\n",
        "        raise TypeError('Object must be a Pandas Series.')\n",
        "\n",
        "# Add the gini index function\n",
        "def gini_index(y):\n",
        "    if isinstance(y, pd.Series):\n",
        "        a = y.value_counts()/y.shape[0]\n",
        "        gini = 1 - np.sum(a**2)\n",
        "        return gini\n",
        "    else:\n",
        "        raise TypeError('Object must be a Pandas Series.')\n",
        "\n",
        "def variance(y):\n",
        "    if len(y) == 1:\n",
        "        return 0\n",
        "    else:\n",
        "        return y.var()\n",
        "\n",
        "def information_gain(y, mask, func=entropy):\n",
        "    a = sum(mask)\n",
        "    b = mask.shape[0] - a\n",
        "\n",
        "    if a == 0 or b == 0:\n",
        "        gain = 0\n",
        "    else:\n",
        "        if y.dtypes != 'O':\n",
        "            gain = variance(y) - (a/(a+b) * variance(y[mask])) - (b/(a+b) * variance(y[~mask]))\n",
        "        else:\n",
        "            gain = func(y) - a/(a+b) * func(y[mask]) - b/(a+b) * func(y[~mask])\n",
        "\n",
        "    return gain\n",
        "\n",
        "def categorical_options(a):\n",
        "    # Creates all possible combinations from a Pandas Series\n",
        "    a = a.unique()\n",
        "\n",
        "    options = []\n",
        "    for L in range(0, len(a)+1):\n",
        "        for subset in itertools.combinations(a, L):\n",
        "            subset = list(subset)\n",
        "            options.append(subset)\n",
        "\n",
        "    return options[1:-1]\n",
        "\n",
        "def max_information_gain_split(x, y, func=entropy):\n",
        "    split_value = []\n",
        "    gain = []\n",
        "\n",
        "    numeric_variable = True if x.dtypes != 'O' else False\n",
        "\n",
        "    if numeric_variable:\n",
        "        options = x.sort_values().unique()[1:]\n",
        "    else:\n",
        "        options = categorical_options(x)\n",
        "\n",
        "    # Calculate gain for all values\n",
        "    for val in options:\n",
        "        mask = x < val if numeric_variable else x.isin(val)\n",
        "        val_gain = information_gain(y, mask, func)\n",
        "        # Append results\n",
        "        gain.append(val_gain)\n",
        "        split_value.append(val)\n",
        "\n",
        "    if len(gain) == 0:\n",
        "        return None, None, None, False\n",
        "\n",
        "    else:\n",
        "        best_gain = max(gain)\n",
        "        best_gain_index = gain.index(best_gain)\n",
        "        best_split = split_value[best_gain_index]\n",
        "        return best_gain, best_split, numeric_variable, True\n",
        "\n",
        "def get_best_split(y, dataset):\n",
        "    masks = dataset.drop(y, axis=1).apply(max_information_gain_split, y=dataset[y])\n",
        "    if sum(masks.loc[3,:]) == 0:\n",
        "        return None, None, None, None\n",
        "\n",
        "    else:\n",
        "        # Get only masks that can be splitted\n",
        "        masks = masks.loc[:,masks.loc[3,:]]\n",
        "\n",
        "        # Get the results for split with highest IG\n",
        "        split_variable = masks.iloc[0].astype(np.float32).idxmax()\n",
        "        split_value = masks[split_variable][1]\n",
        "        split_gain = masks[split_variable][0]\n",
        "        split_numeric = masks[split_variable][2]\n",
        "\n",
        "        return split_variable, split_value, split_gain, split_numeric\n",
        "\n",
        "def make_split(variable, value, dataset, is_numeric):\n",
        "    if is_numeric:\n",
        "        dataset_1 = dataset[dataset[variable] < value]\n",
        "        dataset_2 = dataset[(dataset[variable] < value) == False]\n",
        "    else:\n",
        "        dataset_1 = dataset[dataset[variable].isin(value)]\n",
        "        dataset_2 = dataset[(dataset[variable].isin(value)) == False]\n",
        "\n",
        "    return dataset_1, dataset_2\n",
        "\n",
        "def make_prediction(dataset, target_factor):\n",
        "    if target_factor:\n",
        "        pred = dataset.value_counts().idxmax()\n",
        "    else:\n",
        "        pred = dataset.mean()\n",
        "\n",
        "    return pred\n",
        "\n",
        "def train_tree(dataset, y, target_factor, max_depth=None, min_samples_split=None,\n",
        "               min_information_gain=1e-20, counter=0, max_categories=20, func=entropy):\n",
        "\n",
        "    if counter == 0:\n",
        "        types = dataset.dtypes\n",
        "        check_columns = types[types == \"object\"].index\n",
        "        for column in check_columns:\n",
        "            var_length = len(dataset[column].value_counts())\n",
        "            if var_length > max_categories:\n",
        "                raise ValueError('The variable ' + column + ' has ' + str(var_length) +\n",
        "                                ' unique values, which is more than the accepted ones: ' + str(max_categories))\n",
        "\n",
        "    if max_depth is None:\n",
        "        depth_cond = True\n",
        "    else:\n",
        "        depth_cond = counter < max_depth\n",
        "\n",
        "    if min_samples_split is None:\n",
        "        sample_cond = True\n",
        "    else:\n",
        "        sample_cond = dataset.shape[0] > min_samples_split\n",
        "\n",
        "    if depth_cond and sample_cond:\n",
        "        # Override the function used to calculate information gain\n",
        "        global max_information_gain_split\n",
        "        original_func = max_information_gain_split.__defaults__[0]\n",
        "        max_information_gain_split.__defaults__ = (func,)\n",
        "\n",
        "        var, val, gain, var_type = get_best_split(y, dataset)\n",
        "\n",
        "        # Restore the original function\n",
        "        max_information_gain_split.__defaults__ = (original_func,)\n",
        "\n",
        "        if gain is not None and gain >= min_information_gain:\n",
        "            counter += 1\n",
        "            left, right = make_split(var, val, dataset, var_type)\n",
        "\n",
        "            # Instantiate sub-tree\n",
        "            split_type = \"<=\" if var_type else \"in\"\n",
        "            question = \"{} {} {}\".format(var, split_type, val)\n",
        "            subtree = {question: []}\n",
        "\n",
        "            # Find answers (recursion)\n",
        "            yes_answer = train_tree(left, y, target_factor, max_depth, min_samples_split,\n",
        "                                   min_information_gain, counter, max_categories, func)\n",
        "\n",
        "            no_answer = train_tree(right, y, target_factor, max_depth, min_samples_split,\n",
        "                                  min_information_gain, counter, max_categories, func)\n",
        "\n",
        "            if yes_answer == no_answer:\n",
        "                subtree = yes_answer\n",
        "            else:\n",
        "                subtree[question].append(yes_answer)\n",
        "                subtree[question].append(no_answer)\n",
        "\n",
        "        else:\n",
        "            pred = make_prediction(dataset[y], target_factor)\n",
        "            return pred\n",
        "\n",
        "    else:\n",
        "        pred = make_prediction(dataset[y], target_factor)\n",
        "        return pred\n",
        "\n",
        "    return subtree\n",
        "\n",
        "def classify_data(observation, tree):\n",
        "    question = list(tree.keys())[0]\n",
        "\n",
        "    # Parse the question\n",
        "    parts = question.split()\n",
        "    variable = parts[0]\n",
        "    operator = parts[1]\n",
        "\n",
        "    if operator == '<=':\n",
        "        value = float(parts[2])\n",
        "        if observation[variable] <= value:\n",
        "            answer = tree[question][0]\n",
        "        else:\n",
        "            answer = tree[question][1]\n",
        "    else:  # operator == 'in'\n",
        "        # Safe parsing of the value part which could be a list representation\n",
        "        try:\n",
        "            # Convert string representation of list to actual list\n",
        "            value_str = question[question.find('[')+1:question.find(']')]\n",
        "            value_list = [x.strip(\" '\\\"\") for x in value_str.split(',')]\n",
        "            if observation[variable] in value_list:\n",
        "                answer = tree[question][0]\n",
        "            else:\n",
        "                answer = tree[question][1]\n",
        "        except:\n",
        "            # Fallback for simpler cases\n",
        "            if observation[variable] in eval(parts[2]):\n",
        "                answer = tree[question][0]\n",
        "            else:\n",
        "                answer = tree[question][1]\n",
        "\n",
        "    if not isinstance(answer, dict):\n",
        "        return answer\n",
        "    else:\n",
        "        return classify_data(observation, answer)\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(tree, X, y_true):\n",
        "    y_pred = []\n",
        "    for i, row in X.iterrows():\n",
        "        pred = classify_data(row, tree)\n",
        "        y_pred.append(pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return accuracy, y_pred\n",
        "\n",
        "# Main execution\n",
        "    # Split data\n",
        "    X = dataset.drop('Clicked on Ad', axis=1)\n",
        "    y = dataset['Clicked on Ad']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    train_data = X_train.copy()\n",
        "    train_data['Clicked on Ad'] = y_train\n",
        "\n",
        "    # ---- Task 1: Decision Tree with Entropy ----\n",
        "    print(\"\\n--- Task 1: Decision Tree with Entropy ---\")\n",
        "    max_depth = 5\n",
        "    min_samples_split = 20\n",
        "    min_information_gain = 1e-5\n",
        "\n",
        "    # Train with entropy\n",
        "    tree_entropy = train_tree(train_data, 'Clicked on Ad', True,\n",
        "                             max_depth, min_samples_split, min_information_gain, func=entropy)\n",
        "\n",
        "    # Evaluate entropy model\n",
        "    accuracy_entropy, _ = evaluate_model(tree_entropy, X_test, y_test)\n",
        "    print(f\"Entropy Decision Tree Accuracy: {accuracy_entropy:.4f}\")\n",
        "\n",
        "    # ---- Task 2: Decision Tree with Gini Index ----\n",
        "    print(\"\\n--- Task 2: Decision Tree with Gini Index ---\")\n",
        "\n",
        "    # Train with gini\n",
        "    tree_gini = train_tree(train_data, 'Clicked on Ad', True,\n",
        "                           max_depth, min_samples_split, min_information_gain, func=gini_index)\n",
        "\n",
        "    # Evaluate gini model\n",
        "    accuracy_gini, _ = evaluate_model(tree_gini, X_test, y_test)\n",
        "    print(f\"Gini Index Decision Tree Accuracy: {accuracy_gini:.4f}\")\n",
        "    print(f\"Difference in accuracy: {abs(accuracy_entropy - accuracy_gini):.4f}\")\n",
        "\n",
        "    # ---- Task 3: Scikit-learn Decision Tree ----\n",
        "    print(\"\\n--- Task 3: Scikit-learn Decision Tree ---\")\n",
        "\n",
        "    # Handle categorical variables for sklearn\n",
        "    X_train_proc = pd.get_dummies(X_train.drop(['Ad Topic Line', 'City', 'Country', 'Timestamp'], axis=1))\n",
        "    X_test_proc = pd.get_dummies(X_test.drop(['Ad Topic Line', 'City', 'Country', 'Timestamp'], axis=1))\n",
        "\n",
        "    # Ensure columns match\n",
        "    missing_cols = set(X_train_proc.columns) - set(X_test_proc.columns)\n",
        "    for col in missing_cols:\n",
        "        X_test_proc[col] = 0\n",
        "    X_test_proc = X_test_proc[X_train_proc.columns]\n",
        "\n",
        "    # Train sklearn model with entropy\n",
        "    clf_entropy = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_depth,\n",
        "                                             min_samples_split=min_samples_split, random_state=42)\n",
        "    clf_entropy.fit(X_train_proc, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred_entropy = clf_entropy.predict(X_test_proc)\n",
        "    accuracy_sklearn_entropy = accuracy_score(y_test, y_pred_entropy)\n",
        "    print(f\"Scikit-learn Entropy Decision Tree Accuracy: {accuracy_sklearn_entropy:.4f}\")\n",
        "\n",
        "    # Train sklearn model with gini\n",
        "    clf_gini = tree.DecisionTreeClassifier(criterion='gini', max_depth=max_depth,\n",
        "                                          min_samples_split=min_samples_split, random_state=42)\n",
        "    clf_gini.fit(X_train_proc, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred_gini = clf_gini.predict(X_test_proc)\n",
        "    accuracy_sklearn_gini = accuracy_score(y_test, y_pred_gini)\n",
        "    print(f\"Scikit-learn Gini Decision Tree Accuracy: {accuracy_sklearn_gini:.4f}\")\n",
        "\n",
        "    # Visualize the scikit-learn tree\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    tree.plot_tree(clf_entropy, feature_names=X_train_proc.columns, class_names=['0', '1'], filled=True)\n",
        "    plt.title(\"Decision Tree (Entropy) Visualization\")\n",
        "    plt.savefig(\"decision_tree_entropy.png\")\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    tree.plot_tree(clf_gini, feature_names=X_train_proc.columns, class_names=['0', '1'], filled=True)\n",
        "    plt.title(\"Decision Tree (Gini) Visualization\")\n",
        "    plt.savefig(\"decision_tree_gini.png\")\n",
        "\n",
        "    print(\"\\nTree visualizations saved as decision_tree_entropy.png and decision_tree_gini.png\")\n",
        "\n",
        "    # Compare all methods\n",
        "    print(\"\\n--- Comparison of All Methods ---\")\n",
        "    print(f\"Custom Entropy Decision Tree Accuracy: {accuracy_entropy:.4f}\")\n",
        "    print(f\"Custom Gini Index Decision Tree Accuracy: {accuracy_gini:.4f}\")\n",
        "    print(f\"Scikit-learn Entropy Decision Tree Accuracy: {accuracy_sklearn_entropy:.4f}\")\n",
        "    print(f\"Scikit-learn Gini Decision Tree Accuracy: {accuracy_sklearn_gini:.4f}\")"
      ],
      "metadata": {
        "id": "ej7ApguJvdqS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}