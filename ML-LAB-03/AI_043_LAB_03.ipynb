{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Name:**  Messum Hassan\n",
        "\n",
        "**RollNo** AI-043"
      ],
      "metadata": {
        "id": "sT-2Cy_19zo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Linear Regression**"
      ],
      "metadata": {
        "id": "cX2GMMXjVWLB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJzCElohUgQF",
        "outputId": "eac0b256-f8fe-4705-9a29-694b39bff79b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = 1344612525.8413546\n",
            "Iteration 100: Cost = 55770801.436653785\n",
            "Iteration 200: Cost = 41914253.33688704\n",
            "Iteration 300: Cost = 32841618.722010322\n",
            "Iteration 400: Cost = 26901272.088605642\n",
            "Iteration 500: Cost = 23011804.516844332\n",
            "Iteration 600: Cost = 20465158.8536581\n",
            "Iteration 700: Cost = 18797731.625080306\n",
            "Iteration 800: Cost = 17705976.457569476\n",
            "Iteration 900: Cost = 16991145.05422045\n",
            "\n",
            "Optimized Theta (Intercept and Slope):\n",
            "[[22920.48554852]\n",
            " [ 9876.11275288]]\n"
          ]
        }
      ],
      "source": [
        "# gradient descent and cost function for simple linear regression\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "file_path = \"/content/Salary_Data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "X = df[['YearsExperience']].values\n",
        "y = df[['Salary']].values\n",
        "\n",
        "X = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "theta = np.zeros((2, 1))\n",
        "\n",
        "def compute_cost(X, y, theta):\n",
        "    m = len(y)\n",
        "    predictions = X.dot(theta)\n",
        "    errors = predictions - y\n",
        "    J = (1 / (2 * m)) * np.sum(errors ** 2)\n",
        "    return J\n",
        "\n",
        "def gradient_descent(X, y, theta, alpha, iterations):\n",
        "    m = len(y)\n",
        "    J_history = []\n",
        "\n",
        "    for i in range(iterations):\n",
        "        predictions = X.dot(theta)\n",
        "        errors = predictions - y\n",
        "        gradient = (1 / m) * X.T.dot(errors)\n",
        "        theta -= alpha * gradient\n",
        "\n",
        "        J_history.append(compute_cost(X, y, theta))\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Iteration {i}: Cost = {J_history[-1]}\")\n",
        "\n",
        "    return theta, J_history\n",
        "\n",
        "\n",
        "alpha = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "\n",
        "theta_optimized, J_history = gradient_descent(X, y, theta, alpha, iterations)\n",
        "\n",
        "print(\"\\nOptimized Theta (Intercept and Slope):\")\n",
        "print(theta_optimized)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple Linear Regression**"
      ],
      "metadata": {
        "id": "xVEK8IIU9sTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gradient descent and cost function for multiple linear regression\n",
        "\n",
        "file_path = \"/content/50_Startups.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "X = df[['R&D Spend', 'Administration', 'Marketing Spend']].values\n",
        "y = df['Profit'].values.reshape(-1, 1)\n",
        "\n",
        "\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "\n",
        "m = X.shape[0]\n",
        "X = np.hstack((np.ones((m, 1)), X))\n",
        "\n",
        "\n",
        "theta = np.zeros((X.shape[1], 1))\n",
        "alpha = 0.01\n",
        "num_iters = 1000\n",
        "\n",
        "def compute_cost(X, y, theta):\n",
        "    \"\"\"Compute the cost function for linear regression.\"\"\"\n",
        "    m = len(y)\n",
        "    predictions = X.dot(theta)\n",
        "    errors = predictions - y\n",
        "    cost = (1 / (2 * m)) * np.sum(errors ** 2)\n",
        "    return cost\n",
        "\n",
        "def gradient_descent(X, y, theta, alpha, num_iters):\n",
        "    \"\"\"Perform gradient descent to learn theta.\"\"\"\n",
        "    m = len(y)\n",
        "    cost_history = []\n",
        "\n",
        "    for i in range(num_iters):\n",
        "        gradients = (1 / m) * X.T.dot(X.dot(theta) - y)\n",
        "        theta -= alpha * gradients\n",
        "        cost = compute_cost(X, y, theta)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Iteration {i}: Cost = {cost:.4f}\")\n",
        "\n",
        "    return theta, cost_history\n",
        "\n",
        "\n",
        "theta_optimal, cost_history = gradient_descent(X, y, theta, alpha, num_iters)\n",
        "\n",
        "print(\"Optimized Theta:\", theta_optimal.flatten())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXDSBD3-6ZIW",
        "outputId": "65f648bc-e4fd-47f9-fc24-382dfdc2ea73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = 6920223181.9501\n",
            "Iteration 100: Cost = 922613297.3427\n",
            "Iteration 200: Cost = 175694123.1574\n",
            "Iteration 300: Cost = 70254590.5587\n",
            "Iteration 400: Cost = 51515325.4752\n",
            "Iteration 500: Cost = 46037645.4650\n",
            "Iteration 600: Cost = 43416617.4706\n",
            "Iteration 700: Cost = 41865776.3828\n",
            "Iteration 800: Cost = 40895360.8442\n",
            "Iteration 900: Cost = 40280538.7908\n",
            "Optimized Theta: [112007.80347464  34885.0749308    -135.35668936   4938.40215791]\n"
          ]
        }
      ]
    }
  ]
}